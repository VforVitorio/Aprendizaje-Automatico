{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PL02. Normalization and Standardization of Palmer Penguins Dataset\n",
    "\n",
    "## Performed by Víctor Vega Sobral\n",
    "__Borja González Seoane. Machine Learning. Course 2024-25__\n",
    "\n",
    "For this exercise, as in PL01, the Palmer Penguins dataset will be used again. You will find the CSV `palmer_penguins.csv` in the Virtual Campus. This dataset contains information about penguins of various different species.\n",
    "\n",
    "In this exercise, taking into consideration the EDA analyses from PL01, you should work with Scikit-Learn to normalize and standardize the numerical columns of the dataset. It will probably be useful to use data visualizations to observe the changes from the applied transformations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_FILE = \"palmer_penguins.csv\"\n",
    "\n",
    "df = pd.read_csv(CSV_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection of numerical variables\n",
    "numeric_columns = [\"bill_depth_mm\",\"flipper_length_mm\",\"body_mass_g\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLUMNA ACTUAl: bill_depth_mm\n",
      "Máximo: 21.5\n",
      "Media: 17.151169590643274\n",
      "Mínimo: 13.1\n",
      "COLUMNA ACTUAl: flipper_length_mm\n",
      "Máximo: 231.0\n",
      "Media: 200.91520467836258\n",
      "Mínimo: 172.0\n",
      "COLUMNA ACTUAl: body_mass_g\n",
      "Máximo: 6300.0\n",
      "Media: 4201.754385964912\n",
      "Mínimo: 2700.0\n"
     ]
    }
   ],
   "source": [
    "# Check that it's not normalized\n",
    "for column in numeric_columns:\n",
    "    print(\"\"\"CURRENT COLUMN:\"\"\", column)\n",
    "    print(f\"Maximum: {df[column].max()}\")\n",
    "    print(f\"Mean: {df[column].mean()}\")\n",
    "    print(f\"Minimum: {df[column].min()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La columna actual es: BILL_DEPTH_MM\n",
      "VALORES NORMALIZADOS:\n",
      "Máximo: 1.0\n",
      "Media: 0.48228209412419953\n",
      "Mínimo: 0.0\n",
      "La columna actual es: FLIPPER_LENGTH_MM\n",
      "VALORES NORMALIZADOS:\n",
      "Máximo: 1.0\n",
      "Media: 0.4900882148875014\n",
      "Mínimo: 0.0\n",
      "La columna actual es: BODY_MASS_G\n",
      "VALORES NORMALIZADOS:\n",
      "Máximo: 1.0\n",
      "Media: 0.4171539961013645\n",
      "Mínimo: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Scaler initialization \n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "for column in numeric_columns:\n",
    "    if column in df.columns:\n",
    "        print(f\"The current column is: {column.upper()}\")\n",
    "        # Normalize the column\n",
    "        df[f'{columna}_norm_sklearn'] = scaler.fit_transform(df[[columna]])\n",
    "        print(\"VALORES NORMALIZADOS:\")\n",
    "        print(f\"Máximo: {df[f'{columna}_norm_sklearn'].max()}\")\n",
    "        print(f\"Media: {df[f'{columna}_norm_sklearn'].mean()}\")\n",
    "        print(f\"Mínimo: {df[f'{columna}_norm_sklearn'].min()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mínimo almacenado en el objeto scaler: [2700.]\n",
      "Máximo almacenado en el objeto scaler: [6300.]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mínimo almacenado en el objeto scaler: {scaler.data_min_}\")\n",
    "print(f\"Máximo almacenado en el objeto scaler: {scaler.data_max_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to standardize directly \n",
    "# with the formula from the slides\n",
    "def standardize(df):\n",
    "    return (df - df.mean()) / df.std()\n",
    "\n",
    "for column in numeric_columns:\n",
    "    df[f\"{column}_standard_formula\"] = standardize(df[column])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Z-score standardization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estadísticas del DataFrame original:\n",
      "Medias:\n",
      " bill_depth_mm       -0.001041\n",
      "flipper_length_mm   -0.002759\n",
      "body_mass_g         -0.002925\n",
      "dtype: float64\n",
      "Desviaciones estándar:\n",
      " bill_depth_mm        1.001872\n",
      "flipper_length_mm    1.000626\n",
      "body_mass_g          0.997604\n",
      "dtype: float64\n",
      "\n",
      "Estadísticas del DataFrame normalizado:\n",
      "Medias:\n",
      " bill_depth_mm        4.155221e-16\n",
      "flipper_length_mm   -8.310441e-16\n",
      "body_mass_g          8.310441e-17\n",
      "dtype: float64\n",
      "Desviaciones estándar:\n",
      " bill_depth_mm        1.001465\n",
      "flipper_length_mm    1.001465\n",
      "body_mass_g          1.001465\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "numeric_columns = [\"bill_depth_mm\", \"flipper_length_mm\", \"body_mass_g\"]\n",
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "# Fit the scaler to the numeric columns and transform them\n",
    "df_scaled = scaler.fit_transform(df[numeric_columns])\n",
    "# Convert the result back to a DataFrame\n",
    "df_scaled_df = pd.DataFrame(df_scaled, columns=numeric_columns)\n",
    "# Replace the original columns with the normalized ones in the original DataFrame\n",
    "df[numeric_columns] = df_scaled_df\n",
    "# Print statistics of the original DataFrame\n",
    "print(\"Original DataFrame statistics:\")\n",
    "print(\"Means:\\n\", df[numeric_columns].mean())\n",
    "print(\"Standard deviations:\\n\", df[numeric_columns].std())\n",
    "# Print statistics of the normalized DataFrame\n",
    "print(\"\\nNormalized DataFrame statistics:\")\n",
    "print(\"Means:\\n\", df_scaled_df.mean())\n",
    "print(\"Standard deviations:\\n\", df_scaled_df.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization and standardization are key techniques for preprocessing data before applying machine learning algorithms. These techniques allow improving the performance and accuracy of models by ensuring that the different characteristics of the data are on a comparable scale.\n",
    "\n",
    "By selecting the numerical columns in a list and using loops we can normalize and standardize all of them in many fewer lines."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
