{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PL02. Normalización y Estandarización del Conjunto de Datos _Pingüinos de Palmer_\n",
    "\n",
    "## Realizada por Víctor Vega Sobral\n",
    "__Borja González Seoane. Aprendizaje Automático. Curso 2024-25__\n",
    "\n",
    "Para este ejercicio se volverá a emplear, al igual que en la PL01, el conjunto de datos _Pingüinos de Palmer_. Encontrará el CSV `palmer_penguins.csv` en el Campus Virtual. Este conjunto de datos contiene información sobre pingüinos de varias especies diferentes. \n",
    "\n",
    "En este ejercicio, teniendo en consideración los análisis del EDA de la PL01, se deberá trabajar con Scikit-Learn para normalizar y estandarizar las columnas numéricas del conjunto de datos. Probablemente sea de utilidad emplear visualizaciones de datos para observar los cambios de las transformaciones aplicadas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga del conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_FILE = \"palmer_penguins.csv\"\n",
    "\n",
    "df = pd.read_csv(CSV_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selección de una variable numérica\n",
    "columnas_numericas = [\"bill_depth_mm\",\"flipper_length_mm\",\"body_mass_g\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLUMNA ACTUAl: bill_depth_mm\n",
      "Máximo: 21.5\n",
      "Media: 17.151169590643274\n",
      "Mínimo: 13.1\n",
      "COLUMNA ACTUAl: flipper_length_mm\n",
      "Máximo: 231.0\n",
      "Media: 200.91520467836258\n",
      "Mínimo: 172.0\n",
      "COLUMNA ACTUAl: body_mass_g\n",
      "Máximo: 6300.0\n",
      "Media: 4201.754385964912\n",
      "Mínimo: 2700.0\n"
     ]
    }
   ],
   "source": [
    "# Comprobamos que no esté normalizada\n",
    "for columna in columnas_numericas:\n",
    "    print(\"\"\"COLUMNA ACTUAl:\"\"\", columna)\n",
    "    print(f\"Máximo: {df[columna].max()}\")\n",
    "    print(f\"Media: {df[columna].mean()}\")\n",
    "    print(f\"Mínimo: {df[columna].min()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La columna actual es: BILL_DEPTH_MM\n",
      "VALORES NORMALIZADOS:\n",
      "Máximo: 1.0\n",
      "Media: 0.48228209412419953\n",
      "Mínimo: 0.0\n",
      "La columna actual es: FLIPPER_LENGTH_MM\n",
      "VALORES NORMALIZADOS:\n",
      "Máximo: 1.0\n",
      "Media: 0.4900882148875014\n",
      "Mínimo: 0.0\n",
      "La columna actual es: BODY_MASS_G\n",
      "VALORES NORMALIZADOS:\n",
      "Máximo: 1.0\n",
      "Media: 0.4171539961013645\n",
      "Mínimo: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Inicialización del escalador \n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "for columna in columnas_numericas:\n",
    "    if columna in df.columns:\n",
    "        print(f\"La columna actual es: {columna.upper()}\")\n",
    "        # Normalizar la columna\n",
    "        df[f'{columna}_norm_sklearn'] = scaler.fit_transform(df[[columna]])\n",
    "        print(\"VALORES NORMALIZADOS:\")\n",
    "        print(f\"Máximo: {df[f'{columna}_norm_sklearn'].max()}\")\n",
    "        print(f\"Media: {df[f'{columna}_norm_sklearn'].mean()}\")\n",
    "        print(f\"Mínimo: {df[f'{columna}_norm_sklearn'].min()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mínimo almacenado en el objeto scaler: [2700.]\n",
      "Máximo almacenado en el objeto scaler: [6300.]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mínimo almacenado en el objeto scaler: {scaler.data_min_}\")\n",
    "print(f\"Máximo almacenado en el objeto scaler: {scaler.data_max_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estandarización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para estandardizar directamente \n",
    "# con la fórmula de las transparencias\n",
    "def estandarizar(df):\n",
    "    return (df - df.mean()) / df.std()\n",
    "\n",
    "for columna in columnas_numericas:\n",
    "    df[f\"{columna}_estandar_formula\"] = estandarizar(df[columna])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estandarización por z score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estadísticas del DataFrame original:\n",
      "Medias:\n",
      " bill_depth_mm       -0.001041\n",
      "flipper_length_mm   -0.002759\n",
      "body_mass_g         -0.002925\n",
      "dtype: float64\n",
      "Desviaciones estándar:\n",
      " bill_depth_mm        1.001872\n",
      "flipper_length_mm    1.000626\n",
      "body_mass_g          0.997604\n",
      "dtype: float64\n",
      "\n",
      "Estadísticas del DataFrame normalizado:\n",
      "Medias:\n",
      " bill_depth_mm        4.155221e-16\n",
      "flipper_length_mm   -8.310441e-16\n",
      "body_mass_g          8.310441e-17\n",
      "dtype: float64\n",
      "Desviaciones estándar:\n",
      " bill_depth_mm        1.001465\n",
      "flipper_length_mm    1.001465\n",
      "body_mass_g          1.001465\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "columnas_numericas = [\"bill_depth_mm\", \"flipper_length_mm\", \"body_mass_g\"]\n",
    "# Crear una instancia de StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# Ajustar el scaler a las columnas numéricas y transformarlas\n",
    "df_scaled = scaler.fit_transform(df[columnas_numericas])\n",
    "# Convertir el resultado de vuelta a un DataFrame\n",
    "df_scaled_df = pd.DataFrame(df_scaled, columns=columnas_numericas)\n",
    "# Reemplazar las columnas originales con las normalizadas en el DataFrame original\n",
    "df[columnas_numericas] = df_scaled_df\n",
    "# Imprimir estadísticas del DataFrame original\n",
    "print(\"Estadísticas del DataFrame original:\")\n",
    "print(\"Medias:\\n\", df[columnas_numericas].mean())\n",
    "print(\"Desviaciones estándar:\\n\", df[columnas_numericas].std())\n",
    "# Imprimir estadísticas del DataFrame normalizado\n",
    "print(\"\\nEstadísticas del DataFrame normalizado:\")\n",
    "print(\"Medias:\\n\", df_scaled_df.mean())\n",
    "print(\"Desviaciones estándar:\\n\", df_scaled_df.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La normalización y la estandarización son técnicas clave para preprocesar datos antes de aplicar algoritmos de aprendizaje automático. Estas técnicas permiten mejorar el rendimiento y la precisión de los modelos al asegurar que las distintas características de los datos estén en una escala comparable.\n",
    "\n",
    "Seleccionando las columnas numericas en una lista y usando bucles podemos normalizar y estandarizar todas estas en muchas menos líneas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
