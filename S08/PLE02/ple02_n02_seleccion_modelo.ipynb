{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selección del modelo \n",
    "### Realizado por Víctor Vega Sobral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importación de bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "from sklearn.svm import SVR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Partición del conjunto de datos para test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conjunto de entrenamiento: (504, 5), (504,)\n",
      "Conjunto de prueba: (217, 5), (217,)\n"
     ]
    }
   ],
   "source": [
    "# Cargar los nuevos datos procesados desde el nuevo csv \n",
    "data = pd.read_csv('ple02_gimnasio_procesados.csv')\n",
    "\n",
    "# La columna o variable objetivo es \"Calories_Burned\"\n",
    "X = data.drop('Calories_Burned', axis = 1) # Caracteristicas\n",
    "y = data['Calories_Burned']\n",
    "\n",
    "\n",
    "# División del conjunto de datos\n",
    "X_train, X_test, y_train, y_test =  train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "# Mostrar las dimensiones de los conjuntos resultantes\n",
    "print(f\"Conjunto de entrenamiento: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Conjunto de prueba: {X_test.shape}, {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selección del modelo\n",
    "Se probarán 3 modelos diferentes de la librería Scikit-learn: \n",
    "- Regresión lineal\n",
    "- Máquinas de vectores regresores (SVR)\n",
    "- Regresión de bosque aleatorio \n",
    "\n",
    "#### Pasos a seguir\n",
    "Para los tres modelos, se seguirá el siguiente flujo de trabajo:\n",
    "1. Creación de instancia del modelo\n",
    "2. Entrenamiento del modelo \n",
    "    1. Validación cruzada.\n",
    "    2. Exploración de hiperparámetros.\n",
    "    3. Control de sobreajuste\n",
    "4. Resultados del entrenamiento.\n",
    "\n",
    "Una vez realizados estos 4 pasos, se procederá a la **evaluación** de cada uno de los modelos. De esta forma, podremos hacer la evaluación de los 3 a la vez, viendo rápidamente cuál se ha ajustado mejor a nuestro conjunto de datos. \n",
    "\n",
    "Para cada uno de los 3 modelos se dará una breve explicación para elegir entre GridSearchCV y RandomizedSearchCV. Se tratan de métodos que usan validación cruzada y exploran los hiperparámetros del modelo, por lo que se podrían hacer en pocas líneas de código los dos primeros pasos del punto número 2 en \"pasos a seguir\", definidos anteriormente.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión lineal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Cuadrático Medio: 4093.3050651238923\n",
      "Error Absoluto Medio: 51.74977617337229\n",
      "R²: 0.9389799615223673\n"
     ]
    }
   ],
   "source": [
    "# Crear el modelo de regresión lineal\n",
    "modelo_regresor_lineal = LinearRegression()\n",
    "\n",
    "# Entrenar el modelo\n",
    "modelo_regresor_lineal.fit(X_train, y_train)\n",
    "\n",
    "# Hacer predicciones en el conjunto de prueba\n",
    "y_pred = modelo_regresor_lineal.predict(X_test)\n",
    "\n",
    "ecm = mean_squared_error(y_test, y_pred)\n",
    "eam = mean_absolute_error(y_test, y_pred)\n",
    "r2_reg_lineal = r2_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "print(f\"Error Cuadrático Medio: {ecm}\")\n",
    "print(f\"Error Absoluto Medio: {eam}\")\n",
    "print(f\"R²: {r2_reg_lineal}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validación cruzada para la regresión lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puntuacion del R2: 0.9432094031599286\n",
      "El modelo ha mejorado su precisión en 0.0042294416375613375\n"
     ]
    }
   ],
   "source": [
    "# Se realiza la validación cruzada\n",
    "scores = cross_val_score(modelo_regresor_lineal, X, y, cv= 5, scoring='r2')\n",
    "# Se imprimen los resultados de r^2 para ver si han mejorado\n",
    "\n",
    "r2_reg_lineal_cruzado = scores.mean()\n",
    "print(f\"Puntuacion del R2: {r2_reg_lineal_cruzado}\")\n",
    "\n",
    "# Hacemos la diferencia entre ambos r2 para encontrar la mejoría del modelo\n",
    "\n",
    "print(f\"El modelo ha mejorado su precisión en {r2_reg_lineal_cruzado - r2_reg_lineal}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede observar que, al realizar validación cruzada, el modelo mejora en un  0.004 en r cuadrado.\n",
    "\n",
    "Aunque se trate de una mejoría pequeña, el modelo ha mejorado su capacidad para explicar la variablilidad de los datos. La validación cruzada ayuda a reducir el riesgo de sobreajuste al evaluar el modelo en varios subconjuntos de los datos, brindando un estimado más estable y confiable del rendimiento real del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Máquinas de vectores de soporte regresores (SVR)\n",
    "\n",
    "Se trata de una extensión de las support vector machines (SVM), utilizadas en principio para problemas de clasificación pero ampliadas a problemas de regresión gracias a las SVR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Cuadrático Medio: 67161.34825693294\n",
      "Error Absoluto Medio: 205.81710093568785\n",
      "R²: -0.0011929210371952603\n"
     ]
    }
   ],
   "source": [
    "# Creación de instancia del modelo SVR, ajustando al parámetro rbf\n",
    "\n",
    "modelo_svr = SVR(kernel = 'rbf') \n",
    "\n",
    "# Entrenar el modelo\n",
    "modelo_svr.fit(X_train, y_train)\n",
    "\n",
    "# Hacer las predicciones \n",
    "y_pred = modelo_svr.predict(X_test)\n",
    "# Cálculo de las métricas de evaluación\n",
    "\n",
    "ecm = mean_squared_error(y_test, y_pred)\n",
    "eam = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "r2_svr = r2_score(y_test, y_pred)\n",
    "# Mostrar las métricas de evaluación\n",
    "print(f\"Error Cuadrático Medio: {ecm}\")\n",
    "print(f\"Error Absoluto Medio: {eam}\")\n",
    "print(f\"R²: {r2_svr}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusiones: usar GridSearchCV o RandomizedSearchCV\n",
    "\n",
    "El r2 negativo significa que el modelo no está funcionando como debería, probablement epor no estar ajustando el hiperparámetro correcto.\n",
    "\n",
    "Por tanto, usaremos GridSearchCV o RandomizedSeacrhCV, que son capaces de encontrar la mejor elección de hiperparámetros.\n",
    "\n",
    "En este caso, RandomizedSearch no será tan costoso computacionalmente, por lo que será el que se use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros: {'C': 73.2993941811405, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "Error Cuadrático Medio: 4114.203245320719\n",
      "Error Absoluto Medio: 51.64096987318156\n",
      "R²: 0.9386684265306102\n",
      "El modelo ha mejorado en 0.9398613475678055\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Definir el modelo SVR\n",
    "modelo_svr_cruzado = SVR()\n",
    "\n",
    "# Definir la cuadrícula de hiperparámetros\n",
    "param_dist = {\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'C': uniform(0.1, 100),  # Distribución uniforme entre 0.1 y 100\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "# Configurar RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(modelo_svr_cruzado, \n",
    "                                   param_distributions=param_dist, \n",
    "                                   n_iter=6, \n",
    "                                   cv=5, \n",
    "                                   scoring='neg_mean_squared_error', \n",
    "                                   n_jobs=-1, \n",
    "                                   random_state=42)\n",
    "# Entrenar el modelo con GridSearchCV\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Obtener el mejor modelo\n",
    "mejor_modelo_svr = random_search.best_estimator_\n",
    "\n",
    "# Hacer predicciones en el conjunto de prueba con el mejor modelo\n",
    "y_pred = mejor_modelo_svr.predict(X_test)\n",
    "\n",
    "# Calcular las métricas de evaluación\n",
    "ecm = mean_squared_error(y_test, y_pred)\n",
    "eam = mean_absolute_error(y_test, y_pred)\n",
    "r2_svr_cruzado = r2_score(y_test, y_pred)\n",
    "\n",
    "# Mostrar las métricas de evaluación\n",
    "print(f\"Mejores hiperparámetros: {random_search.best_params_}\")\n",
    "print(f\"Error Cuadrático Medio: {ecm}\")\n",
    "print(f\"Error Absoluto Medio: {eam}\")\n",
    "print(f\"R²: {r2_svr_cruzado}\")\n",
    "\n",
    "print(f\"El modelo ha mejorado en {r2_svr_cruzado - r2_svr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eventos destacables de la aplicación de validación cruzada\n",
    "\n",
    "Pese a que RandomizedSearchCV sea un modelo computacionalmente menos costoso que GridSearchCV, sigue teniendo que hacer un número bastante alto de combinaciones de hiperparámetros, con unas iteraciones que se definen en n_iter.\n",
    "\n",
    "Pese a tener una complejidad computacional mucho menor que GridSearch, sigue dependiendo gravemente del número de pliegues para validación cruzada y el número de iteraciones.\n",
    "\n",
    "A base de prueba y error, he detectado que a partir de las 5 iteraciones con 5 capas el R cuadrado no aumenta su valor, aumentando únicamente y de forma muy drástica el tiempo de ejecución. \n",
    "\n",
    "SVR es un modelo con una complejidad computacional temporal cuadrática (O(N^2)).\n",
    "La complejidad de randomizedsearch es, aproximadamente: \n",
    "\n",
    "$O(\\text{n\\_iter} \\times \\text{cv} \\times C_{\\text{modelo}})$\n",
    "\n",
    "Siendo C(modelo) la complejidad del modelo a probar. Por tanto, con tan solo cinco iteraciones el modelo presenta una complejidad computacional altísima.\n",
    "\n",
    "**Aunque no es competencia de la asignatura como tal, la complejidad computacional puede ser un punto decisivo a la hora de elegir el modelo a usar**.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación de función de comparación\n",
    "\n",
    "Para que sea más fácil la comparacion entre modelos en base a su r2, se va a implementar una función que vaya recibiendo como argumentos un número variable de r2, usando los xargs de Python.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El modelo con el mayor R^2 es el Modelo 1 con un valor de 0.9432.\n",
      "La diferencia con los otros modelos es: ['0.0045']\n"
     ]
    }
   ],
   "source": [
    "def comparar_r2(*r2_values):\n",
    "    \"\"\"\n",
    "    Compara múltiples valores de R^2 para determinar cuál es el mayor y \n",
    "    calcula las diferencias con respecto a los demás.\n",
    "\n",
    "    Parámetros:\n",
    "    - *r2_values: Valores de R^2 a comparar. \n",
    "    Se pueden proporcionar múltiples valores gracias a usar xargs.\n",
    "\n",
    "    Retorno:\n",
    "    - Ninguno (función de comparación).\n",
    "    Con llamada a función:\n",
    "        Índice del mejor modelo.\n",
    "        Diferencia del valor de R^2 frente a los siguientes.\n",
    "    \"\"\"\n",
    "    # Encontrar el R^2 máximo y su índice\n",
    "    mejor_r2 = max(r2_values)\n",
    "    mejor_modelo_index = r2_values.index(mejor_r2) + 1  \n",
    "\n",
    "    # Calcular las diferencias con respecto al mejor R^2\n",
    "    diferencias = [mejor_r2 - r2 for r2 in r2_values if r2 != mejor_r2]\n",
    "\n",
    "    # Mostrar resultados\n",
    "    print(f\"El modelo con el mayor R^2 es el Modelo {mejor_modelo_index} con un valor de {mejor_r2:.4f}.\")\n",
    "    if diferencias:\n",
    "        print(f\"La diferencia con los otros modelos es: {[f'{d:.4f}' for d in diferencias]}\")\n",
    "\n",
    "# Comparación entre el modelo de regresión lineal y SVR\n",
    "comparar_r2(r2_reg_lineal_cruzado, r2_svr_cruzado)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resultados de la prueba\n",
    "De todas formas, al aplicar validación cruzada, se han solventado exitosamnete los problemas del SVR, pasando de un r cuadrado negativo a uno muy cercano al del modelo anterior, con tan solo 0.0014 menos.\n",
    "\n",
    "Se trata de un valor muy positivo si se parte del valor inicial del SVR. No obstante, presenta dos grandes desventajas frente al modelo de regresión lineal:\n",
    "1. **Valor de r2 menor**: pese a ser poca la diferencia, el modelo de regresión lineal sigue siendo menor.\n",
    "\n",
    "2. **Costo computacional muy elevado**: se trata de un modelo con una complejidad computacional mucho más alta. No solo en el propio modelo en si (O(p) frente a O(n^2)), sino también por el costo añadido de usar RandomizedSearchCV, que vuelve el tiempo de ejecución muy elevado. \n",
    "\n",
    "Por tanto, de momento, el mejor modelo sigue siendo el de regresión lineal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest\n",
    "\n",
    "Se trata de un algoritmo que se basa en la idea de construir un conjunto de árboles de decisión y combinar sus resultados para mejorar la precisión y controlar el sobreajuste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Cuadrático Medio: 4118.92731889401\n",
      "Error Absoluto Medio: 52.085806451612896\n",
      "R²: 0.9385980034503298\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Crear el modelo RandomForestRegressor\n",
    "modelo_rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Entrenar el modelo\n",
    "modelo_rf.fit(X_train, y_train)\n",
    "\n",
    "# Hacer predicciones en el conjunto de prueba\n",
    "y_pred = modelo_rf.predict(X_test)\n",
    "\n",
    "# Calcular las métricas de evaluación\n",
    "ecm = mean_squared_error(y_test, y_pred)\n",
    "eam = mean_absolute_error(y_test, y_pred)\n",
    "r2_forest = r2_score(y_test, y_pred)\n",
    "\n",
    "# Mostrar las métricas de evaluación\n",
    "print(f\"Error Cuadrático Medio: {ecm}\")\n",
    "print(f\"Error Absoluto Medio: {eam}\")\n",
    "print(f\"R²: {r2_forest}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validación cruzada para RandomForest\n",
    "\n",
    "Volvemos a usar la función cross_val_score.\n",
    "Posteriormente, se usará la función **comparar_r2()** para ver finalmente las diferencias entre los 3 modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puntuación del R² en validación cruzada: 0.9430592915911001\n",
      "El modelo con el mayor R^2 es el Modelo 1 con un valor de 0.9432.\n",
      "La diferencia con los otros modelos es: ['0.0045', '0.0002']\n"
     ]
    }
   ],
   "source": [
    "# Crear el modelo RandomForestRegressor\n",
    "modelo_rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Realizar la validación cruzada\n",
    "scores = cross_val_score(modelo_rf, X, y, cv=5, scoring='r2')\n",
    "\n",
    "# Calcular la puntuación promedio de R² en la validación cruzada\n",
    "r2_forest_cruzado = scores.mean()\n",
    "print(f\"Puntuación del R² en validación cruzada: {r2_forest_cruzado}\")\n",
    "\n",
    "comparar_r2(r2_reg_lineal_cruzado, r2_svr_cruzado, r2_forest_cruzado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "\n",
    "Una vez realizados los 3 modelos, se pueden extraer las siguientes conclusiones: \n",
    "\n",
    "#### Mejor métrica de evaluación: R^2\n",
    "Pese a usar también el error cuadrático medio y absoluto, la métrica usada para comparar los 3 modelos ha sido finalmente el **$R^2$**. Existen 3 principales razones para usar esta métrica:\n",
    "\n",
    "1. **Interpretación**: $R^2$ proporciona una medida fácil de interpretar, puesto que cuanto más alto sea, mejor explica el modelo los datos. Esto facilita la comparación entre modelos, ya que todos están normalizados en el mismo rango de 0 a 1. \n",
    "\n",
    "2. **Escala y simplicidad**: Se trata de una interpretación mucho más sencilla de ver a simple vista si no se tiene mucho conocimiento de la medida de las unidades que se está usando en el conjunto de datos. En el error cuadrático medio y absoluto, se deben conocer las unidades de medidas (en este caso de calorías) y evaluar este resultado sabiendo la escala del problema y qué tan asumible es ese error. \n",
    "\n",
    "Es decir, se tiene que saber el rango de los datos, por ejemplo entre 0 y 1000, y luego evaluar cuán aceptable es el error. Sin embargo, $R^2$ no posee unidades, por lo que es mucho más fácil de interpretar a simple vista si el modelo ha mejorado o empeorado.\n",
    "\n",
    "Un valor cercano a 0 sugiere que no funciona bien, mientras que cercano a 1 captura bien la relación entre las variables.\n",
    "\n",
    "3. **Contexto de mejora**: en el caso de tener $R^2$ negativos, rápidamente se sabe que el modelo se desempeña peor que simplemente prediciendo la media de la variable de respuesta. \n",
    "\n",
    "Finalmente, el error cuadrático medio y absoluto son dos métricas más difíciles de interpretar a la hora de decidir qué modelo es mejor. Si un modelo tiene un ECM menor, pero otro un $R^2$ más alto, el $R^2$ puede proporcional una mejor visión del desempeño general del modelo.\n",
    "\n",
    "\n",
    "#### Mejor modelo: Regresión lineal.\n",
    "\n",
    "El modelo de regresión lineal ha sido finalmente el que mejor desempeño ha tenido, principalmente por tres razones.\n",
    "\n",
    "- Es el modelo con una menor **complejidad computacional**. Es un modelo que tarda mucho menos en ejecutarse que SVR y RandomForest, con una diferencia aproximada de 3 segundos, valor que sería mucho más alto si se hiciese un mayor número de iteraciones. Se trata de un punto a tener en cuenta a la hora de desplegar un modelo, sobretodo si el conjunto de datos va a ser más grande.\n",
    "\n",
    "- **Modelo más simple**: se trata del modelo con la idea más simple. A la hora de explicar el modelo a otra persona que no tenga conocimientos, explicar la regresión lineal es mucho más facil que SVR o RandomForest, puesto que sólo se debe explicar que predice valores de una variable respecto a otras que dependen de ella. \n",
    "\n",
    "- **Mejor $R^2$**: es el modelo con un mejor $R^2$, aunque las diferencias sean muy pequeñas. Además, si se compara el desempeño de los modelos sin aplicar validación cruzada, se trata de una opción mucho más robusta que SVR, dado que este tenía en principio un $R^2$ negativo.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Siguientes pasos\n",
    "\n",
    "Los pasos siguientes serían los relacionados al despliegue del modelo. Para ello, se debe realizar un archivo de pesos del modelo, que permitan que no se deba ejecutar todo el código todas las veces que se quiera usar el modelo.\n",
    "\n",
    "Finalmente, se podría considerar volver al EDA para probar la eliminación o adición de columnas en el conjunto de datos, con el objetivo de intentar maximizar el valor de R^2.\n",
    "\n",
    "No obstante, el valor de por sí es elevado, por lo que debe valorar la opción de tener un modelo con unas variables intuitivamente menos representativas pero con un ligero mejor desempeño, o por el contrario quedarse con un modelo con un valor de precisión acertado, algo menor, pero con unas variables mucho más intuitivas a la hora de explicar en base a qué variables se ha entrenado el modelo.\n",
    "\n",
    "La decisión queda a gusto del usuario final. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Persistencia del modelo\n",
    "Se usará **joblib**, una opción recomendada para guardar modelos de Scikit-learn, que además es más eficiente que otras opciones como pickle en términos de espacio y velocidad en objetos grandes, como modelos de aprendizaje automático.\n",
    "\n",
    "Además, se trata de una opción más simple a la hora de implementarlo en Python. \n",
    "\n",
    "También se crearán **4 nuevos csv**, cada uno perteneciente a las 4 variables del conjunto de datos de entrenamiento y test, para tener un registro de fiable de con qué datos se ha entrenado y evaluado el modelo. Se trata de un paso útil que evita que haya fallos posteriormente si los datos cambian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puntuacion del R2: 0.9432094031599286\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "# Crear el modelo de regresión lineal\n",
    "modelo_regresor_lineal = LinearRegression()\n",
    "\n",
    "# Realizar la validación cruzada\n",
    "scores = cross_val_score(modelo_regresor_lineal, X, y, cv=5, scoring='r2')\n",
    "r2_reg_lineal_cruzado = scores.mean()\n",
    "print(f\"Puntuacion del R2: {r2_reg_lineal_cruzado}\")\n",
    "\n",
    "# Entrenar el modelo con todos los datos\n",
    "modelo_regresor_lineal.fit(X, y)\n",
    "\n",
    "# Guardar el modelo entrenado\n",
    "joblib.dump(modelo_regresor_lineal, 'modelo_regresion_lineal.pkl')\n",
    "\n",
    "# Guardar los conjuntos de datos en archivos CSV\n",
    "X_train.to_csv('X_train.csv', index=False)\n",
    "X_test.to_csv('X_test.csv', index=False)\n",
    "y_train.to_csv('y_train.csv', index=False)\n",
    "y_test.to_csv('y_test.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carga del modelo para comprobar que ha sido exportado correctamente\n",
    "\n",
    "Para comprobar que funciona correctamente, deberíamos poseer otro conjunto de datos.\n",
    "\n",
    "Esto se debe a que nuestro conjunto de datos actual es con el que se acaba de entrenar el modelo. Por tanto, es probable que al cargarlo de nuevo sobre este, el $R^2$ aumente debido a que ya ha visto anteriormente todos estos datos. \n",
    "\n",
    "Por tanto, se recomienda poseer otro dataset del estilo o nuevos datos para comprobar que el modelo está funcionando correctamente. No obstante, para comprobar que el archivo se ha creado exitosamente y que funciona, se trata de una opción rápida y útil para su propósito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² del modelo cargado: 0.9440224555762704\n"
     ]
    }
   ],
   "source": [
    "# Cargar el modelo guardado\n",
    "modelo_cargado = joblib.load('modelo_regresion_lineal.pkl')\n",
    "# Verificar que el modelo cargado funciona correctamente\n",
    "y_pred_cargado = modelo_cargado.predict(X)\n",
    "\n",
    "r2_cargado = modelo_cargado.score(X, y)\n",
    "\n",
    "print(f\"R² del modelo cargado: {r2_cargado}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
